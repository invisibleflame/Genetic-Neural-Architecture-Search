{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NAS",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import numpy as np\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "EOUjRXWUpcAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import random as rand\n",
        "import csv\n",
        "import operator\n",
        "import gc\n",
        "import os\n",
        "from datetime import datetime\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "import keras.backend as K\n",
        "from sklearn.metrics import log_loss\n",
        "import numpy as np\n",
        "\n",
        "if K.backend() == 'tensorflow':\n",
        "    import tensorflow as tf\n",
        "\n",
        "__all__ = ['DEvol']\n",
        "\n",
        "METRIC_OPS = [operator.__lt__, operator.__gt__]\n",
        "METRIC_OBJECTIVES = [min, max]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DEvol:\n",
        "    \"\"\"\n",
        "    Object which carries out genetic search and returns top performing model\n",
        "    upon completion.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, genome_handler, data_path=\"\"):\n",
        "        \"\"\"\n",
        "        Initialize a DEvol object which carries out the training and evaluation\n",
        "        of a genetic search.\n",
        "        Args:\n",
        "            genome_handler (GenomeHandler): the genome handler object defining\n",
        "                    the restrictions for the architecture search space\n",
        "            data_path (str): the file which the genome encodings and metric data\n",
        "                    will be stored in\n",
        "        \"\"\"\n",
        "        self.genome_handler = genome_handler\n",
        "        self.datafile = data_path or (datetime.now().ctime() + '.csv')\n",
        "        self._bssf = -1\n",
        "\n",
        "        if os.path.isfile(data_path) and os.stat(data_path).st_size > 1:\n",
        "            raise ValueError(('Non-empty file %s already exists. Please change'\n",
        "                              'file path to prevent overwritten genome data.'\n",
        "                              % data_path))\n",
        "\n",
        "        print(\"Genome encoding and metric data stored at\", self.datafile, \"\\n\")\n",
        "        with open(self.datafile, 'a') as csvfile:\n",
        "            writer = csv.writer(csvfile, delimiter=',', quotechar='\"',\n",
        "                                quoting=csv.QUOTE_MINIMAL)\n",
        "            metric_cols = [\"Val Loss\", \"Val Accuracy\"]\n",
        "            genome = genome_handler.genome_representation() + metric_cols\n",
        "            writer.writerow(genome)\n",
        "\n",
        "    def set_objective(self, metric):\n",
        "        \"\"\"\n",
        "        Set the metric for optimization. Can also be done by passing to\n",
        "        `run`.\n",
        "        Args:\n",
        "            metric (str): either 'acc' to maximize classification accuracy, or\n",
        "                    else 'loss' to minimize the loss function\n",
        "        \"\"\"\n",
        "        if metric == 'acc':\n",
        "            metric = 'accuracy'\n",
        "        if metric not in ['loss', 'accuracy']:\n",
        "            raise ValueError(('Invalid metric name {} provided - should be'\n",
        "                              '\"accuracy\" or \"loss\"').format(metric))\n",
        "        self._metric = metric\n",
        "        self._objective = \"max\" if self._metric == \"accuracy\" else \"min\"\n",
        "        self._metric_index = 1 if self._metric == 'loss' else -1\n",
        "        self._metric_op = METRIC_OPS[self._objective == 'max']\n",
        "        self._metric_objective = METRIC_OBJECTIVES[self._objective == 'max']\n",
        "\n",
        "    def run(self, dataset, num_generations, pop_size, epochs, fitness=None,\n",
        "            metric='accuracy'):\n",
        "        \"\"\"\n",
        "        Run genetic search on dataset given number of generations and\n",
        "        population size\n",
        "        Args:\n",
        "            dataset : tuple or list of numpy arrays in form ((train_data,\n",
        "                    train_labels), (validation_data, validation_labels))\n",
        "            num_generations (int): number of generations to search\n",
        "            pop_size (int): initial population size\n",
        "            epochs (int): epochs for each model eval, passed to keras model.fit\n",
        "            fitness (None, optional): scoring function to be applied to\n",
        "                    population scores, will be called on a numpy array which is\n",
        "                    a min/max scaled version of evaluated model metrics, so It\n",
        "                    should accept a real number including 0. If left as default\n",
        "                    just the min/max scaled values will be used.\n",
        "            metric (str, optional): must be \"accuracy\" or \"loss\" , defines what\n",
        "                    to optimize during search\n",
        "        Returns:\n",
        "            keras model: best model found with weights\n",
        "        \"\"\"\n",
        "        self.set_objective(metric)\n",
        "\n",
        "        # If no validation data is given set it to None\n",
        "        if len(dataset) == 2:\n",
        "            (self.x_train, self.y_train), (self.x_test, self.y_test) = dataset\n",
        "            self.x_val = None\n",
        "            self.y_val = None\n",
        "        else:\n",
        "            (self.x_train, self.y_train), (self.x_test, self.y_test), (self.x_val, self.y_val) = dataset\n",
        "\n",
        "        # generate and evaluate initial population\n",
        "        members = self._generate_random_population(pop_size)\n",
        "        pop = self._evaluate_population(members,\n",
        "                                        epochs,\n",
        "                                        fitness,\n",
        "                                        0,\n",
        "                                        num_generations)\n",
        "\n",
        "        # evolve\n",
        "        for gen in range(1, num_generations):\n",
        "            members = self._reproduce(pop, gen)\n",
        "            pop = self._evaluate_population(members,\n",
        "                                            epochs,\n",
        "                                            fitness,\n",
        "                                            gen,\n",
        "                                            num_generations)\n",
        "\n",
        "        return load_model('best-model.h5')\n",
        "\n",
        "    def _reproduce(self, pop, gen):\n",
        "        members = []\n",
        "\n",
        "        # 95% of population from crossover\n",
        "        for _ in range(int(len(pop) * 0.95)):\n",
        "            members.append(self._crossover(pop.select(), pop.select()))\n",
        "\n",
        "        # best models survive automatically\n",
        "        members += pop.get_best(len(pop) - int(len(pop) * 0.95))\n",
        "\n",
        "        # randomly mutate\n",
        "        for imem, mem in enumerate(members):\n",
        "            members[imem] = self._mutate(mem, gen)\n",
        "        return members\n",
        "\n",
        "    def _evaluate(self, genome, epochs):\n",
        "        model = self.genome_handler.decode(genome)\n",
        "        loss, accuracy = None, None\n",
        "        fit_params = {\n",
        "            'x': self.x_train,\n",
        "            'y': self.y_train,\n",
        "            'validation_split': 0.1,\n",
        "            'epochs': epochs,\n",
        "            'verbose': 1,\n",
        "            'callbacks': [\n",
        "                EarlyStopping(monitor='val_loss', patience=1, verbose=1)\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        if self.x_val is not None:\n",
        "            fit_params['validation_data'] = (self.x_val, self.y_val)\n",
        "        try:\n",
        "            model.fit(**fit_params)\n",
        "            loss, accuracy = model.evaluate(self.x_test, self.y_test, verbose=0)\n",
        "        except Exception as e:\n",
        "            loss, accuracy = self._handle_broken_model(model, e)\n",
        "\n",
        "        self._record_stats(model, genome, loss, accuracy)\n",
        "\n",
        "        return model, loss, accuracy\n",
        "\n",
        "    def _record_stats(self, model, genome, loss, accuracy):\n",
        "        with open(self.datafile, 'a') as csvfile:\n",
        "            writer = csv.writer(csvfile, delimiter=',',\n",
        "                                quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "            row = list(genome) + [loss, accuracy]\n",
        "            writer.writerow(row)\n",
        "\n",
        "        met = loss if self._metric == 'loss' else accuracy\n",
        "        if (self._bssf is -1 or\n",
        "                self._metric_op(met, self._bssf) and\n",
        "                accuracy is not 0):\n",
        "            try:\n",
        "                os.remove('best-model.h5')\n",
        "            except OSError:\n",
        "                pass\n",
        "            self._bssf = met\n",
        "            model.save('best-model.h5')\n",
        "\n",
        "    def _handle_broken_model(self, model, error):\n",
        "        del model\n",
        "\n",
        "        n = self.genome_handler.n_classes\n",
        "        loss = log_loss(np.concatenate(([1], np.zeros(n - 1))), np.ones(n) / n)\n",
        "        accuracy = 1 / n\n",
        "        gc.collect()\n",
        "\n",
        "        if K.backend() == 'tensorflow':\n",
        "            K.clear_session()\n",
        "            tf.reset_default_graph()\n",
        "\n",
        "        print('An error occurred and the model could not train:')\n",
        "        print(error)\n",
        "        print(('Model assigned poor score. Please ensure that your model'\n",
        "               'constraints live within your computational resources.'))\n",
        "        return loss, accuracy\n",
        "\n",
        "    def _evaluate_population(self, members, epochs, fitness, igen, ngen):\n",
        "        fit = []\n",
        "        for imem, mem in enumerate(members):\n",
        "            self._print_evaluation(imem, len(members), igen, ngen)\n",
        "            res = self._evaluate(mem, epochs)\n",
        "            v = res[self._metric_index]\n",
        "            del res\n",
        "            fit.append(v)\n",
        "\n",
        "        fit = np.array(fit)\n",
        "        self._print_result(fit, igen)\n",
        "        return _Population(members, fit, fitness, obj=self._objective)\n",
        "\n",
        "    def _print_evaluation(self, imod, nmod, igen, ngen):\n",
        "        fstr = '\\nmodel {0}/{1} - generation {2}/{3}:\\n'\n",
        "        print(fstr.format(imod + 1, nmod, igen + 1, ngen))\n",
        "\n",
        "    def _generate_random_population(self, size):\n",
        "        return [self.genome_handler.generate() for _ in range(size)]\n",
        "\n",
        "    def _print_result(self, fitness, generation):\n",
        "        result_str = ('Generation {3}:\\t\\tbest {4}: {0:0.4f}\\t\\taverage:'\n",
        "                      '{1:0.4f}\\t\\tstd: {2:0.4f}')\n",
        "        print(result_str.format(self._metric_objective(fitness),\n",
        "                                np.mean(fitness),\n",
        "                                np.std(fitness),\n",
        "                                generation + 1, self._metric))\n",
        "\n",
        "    def _crossover(self, genome1, genome2):\n",
        "        cross_ind = rand.randint(0, len(genome1))\n",
        "        child = genome1[:cross_ind] + genome2[cross_ind:]\n",
        "        return child\n",
        "\n",
        "    def _mutate(self, genome, generation):\n",
        "        # increase mutations as program continues\n",
        "        num_mutations = max(3, generation // 4)\n",
        "        return self.genome_handler.mutate(genome, num_mutations)\n",
        "\n",
        "\n",
        "class _Population(object):\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.members)\n",
        "\n",
        "    def __init__(self, members, fitnesses, score, obj='max'):\n",
        "        self.members = members\n",
        "        scores = fitnesses - fitnesses.min()\n",
        "        if scores.max() > 0:\n",
        "            scores /= scores.max()\n",
        "        if obj == 'min':\n",
        "            scores = 1 - scores\n",
        "        if score:\n",
        "            self.scores = score(scores)\n",
        "        else:\n",
        "            self.scores = scores\n",
        "        self.s_fit = sum(self.scores)\n",
        "\n",
        "    def get_best(self, n):\n",
        "        combined = [(self.members[i], self.scores[i])\n",
        "                    for i in range(len(self.members))]\n",
        "        sorted(combined, key=(lambda x: x[1]), reverse=True)\n",
        "        return [x[0] for x in combined[:n]]\n",
        "\n",
        "    def select(self):\n",
        "        dart = rand.uniform(0, self.s_fit)\n",
        "        sum_fits = 0\n",
        "        for i in range(len(self.members)):\n",
        "            sum_fits += self.scores[i]\n",
        "            if sum_fits >= dart:\n",
        "                return self.members[i]"
      ],
      "metadata": {
        "id": "cglXtvQph39x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random as rand\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "class GenomeHandler:\n",
        "    \"\"\"\n",
        "    Defines the configuration and handles the conversion and mutation of\n",
        "    individual genomes. Should be created and passed to a `DEvol` instance.\n",
        "    ---\n",
        "    Genomes are represented as fixed-with lists of integers corresponding\n",
        "    to sequential layers and properties. A model with 2 convolutional layers\n",
        "    and 1 dense layer would look like:\n",
        "    [<conv layer><conv layer><dense layer><optimizer>]\n",
        "    The makeup of the convolutional layers and dense layers is defined in the\n",
        "    GenomeHandler below under self.convolutional_layer_shape and\n",
        "    self.dense_layer_shape. <optimizer> consists of just one property.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_conv_layers, max_dense_layers, max_filters,\n",
        "                 max_dense_nodes, input_shape, n_classes,\n",
        "                 batch_normalization=True, dropout=True, max_pooling=True,\n",
        "                 optimizers=None, activations=None):\n",
        "        \"\"\"\n",
        "        Creates a GenomeHandler according\n",
        "        Args:\n",
        "            max_conv_layers: The maximum number of convolutional layers\n",
        "            max_dense_layers: The maximum number of dense (fully connected)\n",
        "                    layers, including output layer\n",
        "            max_filters: The maximum number of conv filters (feature maps) in a\n",
        "                    convolutional layer\n",
        "            max_dense_nodes: The maximum number of nodes in a dense layer\n",
        "            input_shape: The shape of the input\n",
        "            n_classes: The number of classes\n",
        "            batch_normalization (bool): whether the GP should include batch norm\n",
        "            dropout (bool): whether the GP should include dropout\n",
        "            max_pooling (bool): whether the GP should include max pooling layers\n",
        "            optimizers (list): list of optimizers to be tried by the GP. By\n",
        "                    default, the network uses Keras's built-in adam, rmsprop,\n",
        "                    adagrad, and adadelta\n",
        "            activations (list): list of activation functions to be tried by the\n",
        "                    GP. By default, relu and sigmoid.\n",
        "        \"\"\"\n",
        "        if max_dense_layers < 1:\n",
        "            raise ValueError(\n",
        "                \"At least one dense layer is required for softmax layer\"\n",
        "            )\n",
        "        if max_filters > 0:\n",
        "            filter_range_max = int(math.log(max_filters, 2)) + 1\n",
        "        else:\n",
        "            filter_range_max = 0\n",
        "        self.optimizer = optimizers or [\n",
        "            'adam',\n",
        "            'rmsprop',\n",
        "            'adagrad',\n",
        "            'adadelta'\n",
        "        ]\n",
        "        self.activation = activations or [\n",
        "            'relu',\n",
        "            'sigmoid',\n",
        "        ]\n",
        "        self.convolutional_layer_shape = [\n",
        "            \"active\",\n",
        "            \"num filters\",\n",
        "            \"batch normalization\",\n",
        "            \"activation\",\n",
        "            \"dropout\",\n",
        "            \"max pooling\",\n",
        "        ]\n",
        "        self.dense_layer_shape = [\n",
        "            \"active\",\n",
        "            \"num nodes\",\n",
        "            \"batch normalization\",\n",
        "            \"activation\",\n",
        "            \"dropout\",\n",
        "        ]\n",
        "        self.layer_params = {\n",
        "            \"active\": [0, 1],\n",
        "            \"num filters\": [2**i for i in range(3, filter_range_max)],\n",
        "            \"num nodes\": [2**i for i in range(4, int(math.log(max_dense_nodes, 2)) + 1)],\n",
        "            \"batch normalization\": [0, (1 if batch_normalization else 0)],\n",
        "            \"activation\": list(range(len(self.activation))),\n",
        "            \"dropout\": [(i if dropout else 0) for i in range(11)],\n",
        "            \"max pooling\": list(range(3)) if max_pooling else 0,\n",
        "        }\n",
        "\n",
        "        self.convolution_layers = max_conv_layers\n",
        "        self.convolution_layer_size = len(self.convolutional_layer_shape)\n",
        "        self.dense_layers = max_dense_layers - 1  # this doesn't include the softmax layer, so -1\n",
        "        self.dense_layer_size = len(self.dense_layer_shape)\n",
        "        self.input_shape = input_shape\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def convParam(self, i):\n",
        "        key = self.convolutional_layer_shape[i]\n",
        "        return self.layer_params[key]\n",
        "\n",
        "    def denseParam(self, i):\n",
        "        key = self.dense_layer_shape[i]\n",
        "        return self.layer_params[key]\n",
        "\n",
        "    def mutate(self, genome, num_mutations):\n",
        "        num_mutations = np.random.choice(num_mutations)\n",
        "        for i in range(num_mutations):\n",
        "            index = np.random.choice(list(range(1, len(genome))))\n",
        "            if index < self.convolution_layer_size * self.convolution_layers:\n",
        "                if genome[index - index % self.convolution_layer_size]:\n",
        "                    range_index = index % self.convolution_layer_size\n",
        "                    choice_range = self.convParam(range_index)\n",
        "                    genome[index] = np.random.choice(choice_range)\n",
        "                elif rand.uniform(0, 1) <= 0.01:  # randomly flip deactivated layers\n",
        "                    genome[index - index % self.convolution_layer_size] = 1\n",
        "            elif index != len(genome) - 1:\n",
        "                offset = self.convolution_layer_size * self.convolution_layers\n",
        "                new_index = (index - offset)\n",
        "                present_index = new_index - new_index % self.dense_layer_size\n",
        "                if genome[present_index + offset]:\n",
        "                    range_index = new_index % self.dense_layer_size\n",
        "                    choice_range = self.denseParam(range_index)\n",
        "                    genome[index] = np.random.choice(choice_range)\n",
        "                elif rand.uniform(0, 1) <= 0.01:\n",
        "                    genome[present_index + offset] = 1\n",
        "            else:\n",
        "                genome[index] = np.random.choice(list(range(len(self.optimizer))))\n",
        "        return genome\n",
        "\n",
        "    def decode(self, genome):\n",
        "        if not self.is_compatible_genome(genome):\n",
        "            raise ValueError(\"Invalid genome for specified configs\")\n",
        "        model = Sequential()\n",
        "        dim = 0\n",
        "        offset = 0\n",
        "        if self.convolution_layers > 0:\n",
        "            dim = min(self.input_shape[:-1])  # keep track of smallest dimension\n",
        "        input_layer = True\n",
        "        for i in range(self.convolution_layers):\n",
        "            if genome[offset]:\n",
        "                convolution = None\n",
        "                if input_layer:\n",
        "                    convolution = Convolution2D(\n",
        "                        genome[offset + 1], (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=self.input_shape\n",
        "                    )\n",
        "                    input_layer = False\n",
        "                else:\n",
        "                    convolution = Convolution2D(\n",
        "                        genome[offset + 1], (3, 3),\n",
        "                        padding='same'\n",
        "                    )\n",
        "                model.add(convolution)\n",
        "                if genome[offset + 2]:\n",
        "                    model.add(BatchNormalization())\n",
        "                model.add(Activation(self.activation[genome[offset + 3]]))\n",
        "                model.add(Dropout(float(genome[offset + 4] / 20.0)))\n",
        "                max_pooling_type = genome[offset + 5]\n",
        "                # must be large enough for a convolution\n",
        "                if max_pooling_type == 1 and dim >= 5:\n",
        "                    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
        "                    dim = int(math.ceil(dim / 2))\n",
        "            offset += self.convolution_layer_size\n",
        "\n",
        "        if not input_layer:\n",
        "            model.add(Flatten())\n",
        "\n",
        "        for i in range(self.dense_layers):\n",
        "            if genome[offset]:\n",
        "                dense = None\n",
        "                if input_layer:\n",
        "                    dense = Dense(genome[offset + 1], input_shape=self.input_shape)\n",
        "                    input_layer = False\n",
        "                else:\n",
        "                    dense = Dense(genome[offset + 1])\n",
        "                model.add(dense)\n",
        "                if genome[offset + 2]:\n",
        "                    model.add(BatchNormalization())\n",
        "                model.add(Activation(self.activation[genome[offset + 3]]))\n",
        "                model.add(Dropout(float(genome[offset + 4] / 20.0)))\n",
        "            offset += self.dense_layer_size\n",
        "\n",
        "        model.add(Dense(self.n_classes, activation='softmax'))\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=self.optimizer[genome[offset]],\n",
        "                      metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "    def genome_representation(self):\n",
        "        encoding = []\n",
        "        for i in range(self.convolution_layers):\n",
        "            for key in self.convolutional_layer_shape:\n",
        "                encoding.append(\"Conv\" + str(i) + \" \" + key)\n",
        "        for i in range(self.dense_layers):\n",
        "            for key in self.dense_layer_shape:\n",
        "                encoding.append(\"Dense\" + str(i) + \" \" + key)\n",
        "        encoding.append(\"Optimizer\")\n",
        "        return encoding\n",
        "\n",
        "    def generate(self):\n",
        "        genome = []\n",
        "        for i in range(self.convolution_layers):\n",
        "            for key in self.convolutional_layer_shape:\n",
        "                param = self.layer_params[key]\n",
        "                genome.append(np.random.choice(param))\n",
        "        for i in range(self.dense_layers):\n",
        "            for key in self.dense_layer_shape:\n",
        "                param = self.layer_params[key]\n",
        "                genome.append(np.random.choice(param))\n",
        "        genome.append(np.random.choice(list(range(len(self.optimizer)))))\n",
        "        genome[0] = 1\n",
        "        return genome\n",
        "\n",
        "    def is_compatible_genome(self, genome):\n",
        "        expected_len = self.convolution_layers * self.convolution_layer_size \\\n",
        "            + self.dense_layers * self.dense_layer_size + 1\n",
        "        if len(genome) != expected_len:\n",
        "            return False\n",
        "        ind = 0\n",
        "        for i in range(self.convolution_layers):\n",
        "            for j in range(self.convolution_layer_size):\n",
        "                if genome[ind + j] not in self.convParam(j):\n",
        "                    return False\n",
        "            ind += self.convolution_layer_size\n",
        "        for i in range(self.dense_layers):\n",
        "            for j in range(self.dense_layer_size):\n",
        "                if genome[ind + j] not in self.denseParam(j):\n",
        "                    return False\n",
        "            ind += self.dense_layer_size\n",
        "        if genome[ind] not in range(len(self.optimizer)):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def best_genome(self, csv_path, metric=\"accuracy\", include_metrics=True):\n",
        "        best = max if metric is \"accuracy\" else min\n",
        "        col = -1 if metric is \"accuracy\" else -2\n",
        "        data = np.genfromtxt(csv_path, delimiter=\",\")\n",
        "        row = list(data[:, col]).index(best(data[:, col]))\n",
        "        genome = list(map(int, data[row, :-2]))\n",
        "        if include_metrics:\n",
        "            genome += list(data[row, -2:])\n",
        "        return genome\n",
        "\n",
        "    def decode_best(self, csv_path, metric=\"accuracy\"):\n",
        "        return self.decode(self.best_genome(csv_path, metric, False))"
      ],
      "metadata": {
        "id": "y3HB9ytIh_OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "XiikLwPTpr8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K.set_image_data_format(\"channels_last\")\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "dataset = ((x_train, y_train), (x_test, y_test))"
      ],
      "metadata": {
        "id": "LUq4EPwCp2MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genome_handler = GenomeHandler(max_conv_layers=6, \n",
        "                               max_dense_layers=2, # includes final dense layer\n",
        "                               max_filters=256,\n",
        "                               max_dense_nodes=1024,\n",
        "                               input_shape=x_train.shape[1:],\n",
        "                               n_classes=10)"
      ],
      "metadata": {
        "id": "U-gjwWa1p4En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "devol = DEvol(genome_handler)\n",
        "model = devol.run(dataset=dataset,\n",
        "                  num_generations=20,\n",
        "                  pop_size=2,\n",
        "                  epochs=5)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1o_C8mPp6wJ",
        "outputId": "00e783b5-7dd7-4059-e5e5-9ad462058e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genome encoding and metric data stored at Sun Jun 26 11:01:25 2022.csv \n",
            "\n",
            "\n",
            "model 1/2 - generation 1/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 13s 7ms/step - loss: 0.7263 - accuracy: 0.7974 - val_loss: 0.2288 - val_accuracy: 0.9340\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.3089 - accuracy: 0.9141 - val_loss: 0.2295 - val_accuracy: 0.9338\n",
            "Epoch 2: early stopping\n",
            "\n",
            "model 2/2 - generation 1/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 14s 8ms/step - loss: 2.5340 - accuracy: 0.1114 - val_loss: 2.1088 - val_accuracy: 0.2552\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 14s 8ms/step - loss: 1.5895 - accuracy: 0.4616 - val_loss: 0.6601 - val_accuracy: 0.8318\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 14s 8ms/step - loss: 0.6965 - accuracy: 0.7861 - val_loss: 0.4426 - val_accuracy: 0.8787\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 14s 8ms/step - loss: 0.5515 - accuracy: 0.8309 - val_loss: 0.3848 - val_accuracy: 0.8888\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 14s 8ms/step - loss: 0.4980 - accuracy: 0.8493 - val_loss: 0.3571 - val_accuracy: 0.8968\n",
            "Generation 1:\t\tbest accuracy: 0.9287\t\taverage:0.9041\t\tstd: 0.0246\n",
            "\n",
            "model 1/2 - generation 2/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 13s 7ms/step - loss: 0.7243 - accuracy: 0.7998 - val_loss: 0.2895 - val_accuracy: 0.9192\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.3060 - accuracy: 0.9160 - val_loss: 0.1300 - val_accuracy: 0.9675\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2145 - accuracy: 0.9433 - val_loss: 0.1220 - val_accuracy: 0.9698\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.1760 - accuracy: 0.9543 - val_loss: 0.1330 - val_accuracy: 0.9687\n",
            "Epoch 4: early stopping\n",
            "\n",
            "model 2/2 - generation 2/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 13s 7ms/step - loss: 0.7240 - accuracy: 0.7981 - val_loss: 0.2165 - val_accuracy: 0.9385\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2672 - accuracy: 0.9258 - val_loss: 0.1320 - val_accuracy: 0.9657\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.1985 - accuracy: 0.9471 - val_loss: 0.0982 - val_accuracy: 0.9768\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.1687 - accuracy: 0.9551 - val_loss: 0.1059 - val_accuracy: 0.9758\n",
            "Epoch 4: early stopping\n",
            "Generation 2:\t\tbest accuracy: 0.9717\t\taverage:0.9690\t\tstd: 0.0028\n",
            "\n",
            "model 1/2 - generation 3/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 13s 7ms/step - loss: 0.7527 - accuracy: 0.7934 - val_loss: 0.3678 - val_accuracy: 0.8937\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.3707 - accuracy: 0.9001 - val_loss: 0.2363 - val_accuracy: 0.9312\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2250 - accuracy: 0.9374 - val_loss: 0.1603 - val_accuracy: 0.9602\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.1791 - accuracy: 0.9515 - val_loss: 0.1168 - val_accuracy: 0.9693\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.1560 - accuracy: 0.9581 - val_loss: 0.0953 - val_accuracy: 0.9772\n",
            "\n",
            "model 2/2 - generation 3/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 14s 8ms/step - loss: 0.7175 - accuracy: 0.8010 - val_loss: 0.3417 - val_accuracy: 0.9060\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.3316 - accuracy: 0.9094 - val_loss: 0.2482 - val_accuracy: 0.9318\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2098 - accuracy: 0.9423 - val_loss: 0.1189 - val_accuracy: 0.9697\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.1647 - accuracy: 0.9555 - val_loss: 0.1196 - val_accuracy: 0.9690\n",
            "Epoch 4: early stopping\n",
            "Generation 3:\t\tbest accuracy: 0.9752\t\taverage:0.9706\t\tstd: 0.0046\n",
            "\n",
            "model 1/2 - generation 4/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 13s 7ms/step - loss: 0.7273 - accuracy: 0.7984 - val_loss: 0.4018 - val_accuracy: 0.8843\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.3080 - accuracy: 0.9134 - val_loss: 0.1405 - val_accuracy: 0.9635\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2032 - accuracy: 0.9441 - val_loss: 0.1314 - val_accuracy: 0.9658\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.1719 - accuracy: 0.9527 - val_loss: 0.0936 - val_accuracy: 0.9767\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.1508 - accuracy: 0.9590 - val_loss: 0.0988 - val_accuracy: 0.9778\n",
            "Epoch 5: early stopping\n",
            "\n",
            "model 2/2 - generation 4/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 13s 7ms/step - loss: 0.7428 - accuracy: 0.7943 - val_loss: 0.2073 - val_accuracy: 0.9407\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 13s 7ms/step - loss: 0.3208 - accuracy: 0.9135 - val_loss: 0.1813 - val_accuracy: 0.9523\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2093 - accuracy: 0.9437 - val_loss: 0.1021 - val_accuracy: 0.9732\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.1715 - accuracy: 0.9545 - val_loss: 0.2727 - val_accuracy: 0.9443\n",
            "Epoch 4: early stopping\n",
            "Generation 4:\t\tbest accuracy: 0.9744\t\taverage:0.9581\t\tstd: 0.0163\n",
            "\n",
            "model 1/2 - generation 5/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.4795 - accuracy: 0.8579 - val_loss: 0.1799 - val_accuracy: 0.9528\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1880 - accuracy: 0.9450 - val_loss: 0.0913 - val_accuracy: 0.9755\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1256 - accuracy: 0.9626 - val_loss: 0.0813 - val_accuracy: 0.9793\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1081 - accuracy: 0.9684 - val_loss: 0.0744 - val_accuracy: 0.9815\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0974 - accuracy: 0.9717 - val_loss: 0.0684 - val_accuracy: 0.9818\n",
            "\n",
            "model 2/2 - generation 5/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 13s 7ms/step - loss: 0.3323 - accuracy: 0.9038 - val_loss: 0.1123 - val_accuracy: 0.9697\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.1188 - accuracy: 0.9649 - val_loss: 0.0646 - val_accuracy: 0.9808\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0945 - accuracy: 0.9722 - val_loss: 0.0641 - val_accuracy: 0.9823\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0868 - accuracy: 0.9743 - val_loss: 0.0531 - val_accuracy: 0.9853\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0782 - accuracy: 0.9765 - val_loss: 0.0523 - val_accuracy: 0.9855\n",
            "Generation 5:\t\tbest accuracy: 0.9843\t\taverage:0.9815\t\tstd: 0.0028\n",
            "\n",
            "model 1/2 - generation 6/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 14s 8ms/step - loss: 1.7744 - accuracy: 0.3336 - val_loss: 0.9209 - val_accuracy: 0.8290\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 13s 8ms/step - loss: 0.9971 - accuracy: 0.6460 - val_loss: 0.2418 - val_accuracy: 0.9460\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 13s 8ms/step - loss: 0.6523 - accuracy: 0.7808 - val_loss: 0.1240 - val_accuracy: 0.9643\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 13s 8ms/step - loss: 0.4184 - accuracy: 0.8708 - val_loss: 0.1257 - val_accuracy: 0.9705\n",
            "Epoch 4: early stopping\n",
            "\n",
            "model 2/2 - generation 6/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.4898 - accuracy: 0.8547 - val_loss: 0.2095 - val_accuracy: 0.9400\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2098 - accuracy: 0.9384 - val_loss: 0.0980 - val_accuracy: 0.9747\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1298 - accuracy: 0.9628 - val_loss: 0.0799 - val_accuracy: 0.9783\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1095 - accuracy: 0.9679 - val_loss: 0.0716 - val_accuracy: 0.9817\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1009 - accuracy: 0.9714 - val_loss: 0.0632 - val_accuracy: 0.9828\n",
            "Generation 6:\t\tbest accuracy: 0.9796\t\taverage:0.9731\t\tstd: 0.0065\n",
            "\n",
            "model 1/2 - generation 7/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.5096 - accuracy: 0.8475 - val_loss: 0.1918 - val_accuracy: 0.9448\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2070 - accuracy: 0.9398 - val_loss: 0.0943 - val_accuracy: 0.9745\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1297 - accuracy: 0.9625 - val_loss: 0.0711 - val_accuracy: 0.9817\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1062 - accuracy: 0.9688 - val_loss: 0.0685 - val_accuracy: 0.9827\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0953 - accuracy: 0.9721 - val_loss: 0.0644 - val_accuracy: 0.9838\n",
            "\n",
            "model 2/2 - generation 7/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 14s 8ms/step - loss: 2.3057 - accuracy: 0.1128 - val_loss: 2.3022 - val_accuracy: 0.1050\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 13s 8ms/step - loss: 2.0158 - accuracy: 0.2217 - val_loss: 0.9670 - val_accuracy: 0.7787\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 13s 8ms/step - loss: 1.1732 - accuracy: 0.5870 - val_loss: 0.3949 - val_accuracy: 0.9392\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 13s 8ms/step - loss: 0.8139 - accuracy: 0.7185 - val_loss: 0.3026 - val_accuracy: 0.9343\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 13s 8ms/step - loss: 0.5866 - accuracy: 0.8109 - val_loss: 0.1683 - val_accuracy: 0.9630\n",
            "Generation 7:\t\tbest accuracy: 0.9795\t\taverage:0.9674\t\tstd: 0.0121\n",
            "\n",
            "model 1/2 - generation 8/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.4818 - accuracy: 0.8653 - val_loss: 0.1349 - val_accuracy: 0.9622\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1415 - accuracy: 0.9588 - val_loss: 0.0827 - val_accuracy: 0.9785\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1054 - accuracy: 0.9695 - val_loss: 0.0697 - val_accuracy: 0.9825\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.0700 - val_accuracy: 0.9817\n",
            "Epoch 4: early stopping\n",
            "\n",
            "model 2/2 - generation 8/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.4909 - accuracy: 0.8544 - val_loss: 0.2198 - val_accuracy: 0.9370\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2238 - accuracy: 0.9348 - val_loss: 0.1042 - val_accuracy: 0.9727\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1352 - accuracy: 0.9604 - val_loss: 0.0774 - val_accuracy: 0.9785\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1121 - accuracy: 0.9674 - val_loss: 0.0752 - val_accuracy: 0.9793\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0994 - accuracy: 0.9704 - val_loss: 0.0655 - val_accuracy: 0.9823\n",
            "Generation 8:\t\tbest accuracy: 0.9805\t\taverage:0.9796\t\tstd: 0.0009\n",
            "\n",
            "model 1/2 - generation 9/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.5069 - accuracy: 0.8404 - val_loss: 0.1516 - val_accuracy: 0.9563\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1990 - accuracy: 0.9420 - val_loss: 0.1161 - val_accuracy: 0.9698\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1554 - accuracy: 0.9540 - val_loss: 0.0987 - val_accuracy: 0.9743\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1310 - accuracy: 0.9623 - val_loss: 0.0759 - val_accuracy: 0.9797\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1167 - accuracy: 0.9654 - val_loss: 0.0695 - val_accuracy: 0.9813\n",
            "\n",
            "model 2/2 - generation 9/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.4694 - accuracy: 0.8719 - val_loss: 0.1253 - val_accuracy: 0.9667\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1315 - accuracy: 0.9622 - val_loss: 0.0783 - val_accuracy: 0.9795\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1024 - accuracy: 0.9709 - val_loss: 0.0673 - val_accuracy: 0.9827\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0921 - accuracy: 0.9735 - val_loss: 0.0638 - val_accuracy: 0.9835\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0866 - accuracy: 0.9747 - val_loss: 0.0624 - val_accuracy: 0.9835\n",
            "Generation 9:\t\tbest accuracy: 0.9810\t\taverage:0.9787\t\tstd: 0.0024\n",
            "\n",
            "model 1/2 - generation 10/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.5239 - accuracy: 0.8583 - val_loss: 0.1344 - val_accuracy: 0.9622\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1417 - accuracy: 0.9588 - val_loss: 0.0872 - val_accuracy: 0.9757\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1056 - accuracy: 0.9693 - val_loss: 0.0759 - val_accuracy: 0.9815\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0924 - accuracy: 0.9735 - val_loss: 0.0678 - val_accuracy: 0.9827\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0884 - accuracy: 0.9736 - val_loss: 0.0620 - val_accuracy: 0.9840\n",
            "\n",
            "model 2/2 - generation 10/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.5153 - accuracy: 0.8466 - val_loss: 0.2352 - val_accuracy: 0.9322\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2646 - accuracy: 0.9232 - val_loss: 0.1530 - val_accuracy: 0.9550\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1585 - accuracy: 0.9553 - val_loss: 0.0944 - val_accuracy: 0.9747\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1244 - accuracy: 0.9632 - val_loss: 0.0846 - val_accuracy: 0.9788\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1115 - accuracy: 0.9672 - val_loss: 0.0775 - val_accuracy: 0.9802\n",
            "Generation 10:\t\tbest accuracy: 0.9808\t\taverage:0.9782\t\tstd: 0.0026\n",
            "\n",
            "model 1/2 - generation 11/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.5252 - accuracy: 0.8585 - val_loss: 0.1522 - val_accuracy: 0.9582\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1501 - accuracy: 0.9568 - val_loss: 0.0788 - val_accuracy: 0.9815\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1082 - accuracy: 0.9682 - val_loss: 0.0741 - val_accuracy: 0.9810\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0966 - accuracy: 0.9719 - val_loss: 0.0668 - val_accuracy: 0.9840\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0908 - accuracy: 0.9739 - val_loss: 0.0635 - val_accuracy: 0.9837\n",
            "\n",
            "model 2/2 - generation 11/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.4715 - accuracy: 0.8680 - val_loss: 0.1293 - val_accuracy: 0.9667\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1519 - accuracy: 0.9561 - val_loss: 0.0894 - val_accuracy: 0.9748\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1133 - accuracy: 0.9678 - val_loss: 0.0699 - val_accuracy: 0.9825\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0969 - accuracy: 0.9716 - val_loss: 0.0682 - val_accuracy: 0.9845\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0883 - accuracy: 0.9746 - val_loss: 0.0631 - val_accuracy: 0.9842\n",
            "Generation 11:\t\tbest accuracy: 0.9806\t\taverage:0.9805\t\tstd: 0.0001\n",
            "\n",
            "model 1/2 - generation 12/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.4925 - accuracy: 0.8646 - val_loss: 0.1526 - val_accuracy: 0.9545\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1450 - accuracy: 0.9577 - val_loss: 0.0840 - val_accuracy: 0.9772\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1058 - accuracy: 0.9696 - val_loss: 0.0699 - val_accuracy: 0.9817\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0935 - accuracy: 0.9731 - val_loss: 0.0686 - val_accuracy: 0.9832\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0899 - accuracy: 0.9742 - val_loss: 0.0624 - val_accuracy: 0.9833\n",
            "\n",
            "model 2/2 - generation 12/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.4899 - accuracy: 0.8635 - val_loss: 0.1304 - val_accuracy: 0.9627\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1411 - accuracy: 0.9578 - val_loss: 0.0806 - val_accuracy: 0.9773\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1073 - accuracy: 0.9688 - val_loss: 0.0710 - val_accuracy: 0.9817\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0980 - accuracy: 0.9714 - val_loss: 0.0669 - val_accuracy: 0.9828\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0911 - accuracy: 0.9732 - val_loss: 0.0647 - val_accuracy: 0.9838\n",
            "Generation 12:\t\tbest accuracy: 0.9808\t\taverage:0.9807\t\tstd: 0.0000\n",
            "\n",
            "model 1/2 - generation 13/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.4070 - accuracy: 0.8817 - val_loss: 0.1136 - val_accuracy: 0.9692\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1376 - accuracy: 0.9602 - val_loss: 0.0797 - val_accuracy: 0.9805\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1068 - accuracy: 0.9699 - val_loss: 0.0815 - val_accuracy: 0.9790\n",
            "Epoch 3: early stopping\n",
            "\n",
            "model 2/2 - generation 13/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.5001 - accuracy: 0.8652 - val_loss: 0.1218 - val_accuracy: 0.9682\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1397 - accuracy: 0.9595 - val_loss: 0.0816 - val_accuracy: 0.9792\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1074 - accuracy: 0.9686 - val_loss: 0.0681 - val_accuracy: 0.9828\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0950 - accuracy: 0.9724 - val_loss: 0.0657 - val_accuracy: 0.9830\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0901 - accuracy: 0.9737 - val_loss: 0.0627 - val_accuracy: 0.9847\n",
            "Generation 13:\t\tbest accuracy: 0.9806\t\taverage:0.9781\t\tstd: 0.0025\n",
            "\n",
            "model 1/2 - generation 14/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.4678 - accuracy: 0.8700 - val_loss: 0.1279 - val_accuracy: 0.9647\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1339 - accuracy: 0.9611 - val_loss: 0.0801 - val_accuracy: 0.9795\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1056 - accuracy: 0.9692 - val_loss: 0.0713 - val_accuracy: 0.9818\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0957 - accuracy: 0.9720 - val_loss: 0.0666 - val_accuracy: 0.9827\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0891 - accuracy: 0.9742 - val_loss: 0.0624 - val_accuracy: 0.9832\n",
            "\n",
            "model 2/2 - generation 14/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.3937 - accuracy: 0.8885 - val_loss: 0.1061 - val_accuracy: 0.9720\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1247 - accuracy: 0.9645 - val_loss: 0.0788 - val_accuracy: 0.9798\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1024 - accuracy: 0.9709 - val_loss: 0.0716 - val_accuracy: 0.9828\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0937 - accuracy: 0.9726 - val_loss: 0.0694 - val_accuracy: 0.9823\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0932 - accuracy: 0.9738 - val_loss: 0.0646 - val_accuracy: 0.9837\n",
            "Generation 14:\t\tbest accuracy: 0.9809\t\taverage:0.9808\t\tstd: 0.0001\n",
            "\n",
            "model 1/2 - generation 15/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.3830 - accuracy: 0.8899 - val_loss: 0.1201 - val_accuracy: 0.9673\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1218 - accuracy: 0.9646 - val_loss: 0.0748 - val_accuracy: 0.9810\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0986 - accuracy: 0.9716 - val_loss: 0.0734 - val_accuracy: 0.9820\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0938 - accuracy: 0.9730 - val_loss: 0.0695 - val_accuracy: 0.9830\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0892 - accuracy: 0.9745 - val_loss: 0.0616 - val_accuracy: 0.9838\n",
            "\n",
            "model 2/2 - generation 15/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 10s 5ms/step - loss: 0.4820 - accuracy: 0.8689 - val_loss: 0.1567 - val_accuracy: 0.9607\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1430 - accuracy: 0.9581 - val_loss: 0.0843 - val_accuracy: 0.9775\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1070 - accuracy: 0.9685 - val_loss: 0.0686 - val_accuracy: 0.9822\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0961 - accuracy: 0.9718 - val_loss: 0.0658 - val_accuracy: 0.9833\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0907 - accuracy: 0.9738 - val_loss: 0.0626 - val_accuracy: 0.9840\n",
            "Generation 15:\t\tbest accuracy: 0.9819\t\taverage:0.9812\t\tstd: 0.0007\n",
            "\n",
            "model 1/2 - generation 16/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.3833 - accuracy: 0.8915 - val_loss: 0.1039 - val_accuracy: 0.9720\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1186 - accuracy: 0.9655 - val_loss: 0.0798 - val_accuracy: 0.9782\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0981 - accuracy: 0.9719 - val_loss: 0.0652 - val_accuracy: 0.9830\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0898 - accuracy: 0.9742 - val_loss: 0.0763 - val_accuracy: 0.9802\n",
            "Epoch 4: early stopping\n",
            "\n",
            "model 2/2 - generation 16/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.4288 - accuracy: 0.8758 - val_loss: 0.1276 - val_accuracy: 0.9658\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1402 - accuracy: 0.9595 - val_loss: 0.0837 - val_accuracy: 0.9800\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1033 - accuracy: 0.9701 - val_loss: 0.0660 - val_accuracy: 0.9843\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0910 - accuracy: 0.9741 - val_loss: 0.0642 - val_accuracy: 0.9845\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0872 - accuracy: 0.9746 - val_loss: 0.0579 - val_accuracy: 0.9847\n",
            "Generation 16:\t\tbest accuracy: 0.9814\t\taverage:0.9793\t\tstd: 0.0021\n",
            "\n",
            "model 1/2 - generation 17/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.3058 - accuracy: 0.9115 - val_loss: 0.1047 - val_accuracy: 0.9742\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 0.1183 - accuracy: 0.9659 - val_loss: 0.0801 - val_accuracy: 0.9807\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0979 - accuracy: 0.9729 - val_loss: 0.0656 - val_accuracy: 0.9835\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0941 - accuracy: 0.9737 - val_loss: 0.0706 - val_accuracy: 0.9827\n",
            "Epoch 4: early stopping\n",
            "\n",
            "model 2/2 - generation 17/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.4069 - accuracy: 0.8855 - val_loss: 0.1107 - val_accuracy: 0.9692\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1269 - accuracy: 0.9624 - val_loss: 0.0764 - val_accuracy: 0.9810\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1012 - accuracy: 0.9704 - val_loss: 0.0683 - val_accuracy: 0.9848\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0909 - accuracy: 0.9739 - val_loss: 0.0704 - val_accuracy: 0.9827\n",
            "Epoch 4: early stopping\n",
            "Generation 17:\t\tbest accuracy: 0.9792\t\taverage:0.9791\t\tstd: 0.0001\n",
            "\n",
            "model 1/2 - generation 18/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.3295 - accuracy: 0.9036 - val_loss: 0.0922 - val_accuracy: 0.9743\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.1194 - accuracy: 0.9654 - val_loss: 0.0738 - val_accuracy: 0.9820\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 0.1015 - accuracy: 0.9719 - val_loss: 0.0691 - val_accuracy: 0.9835\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0952 - accuracy: 0.9731 - val_loss: 0.0685 - val_accuracy: 0.9835\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.0918 - accuracy: 0.9742 - val_loss: 0.0625 - val_accuracy: 0.9843\n",
            "\n",
            "model 2/2 - generation 18/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.3291 - accuracy: 0.9044 - val_loss: 0.1158 - val_accuracy: 0.9695\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.1303 - accuracy: 0.9627 - val_loss: 0.0824 - val_accuracy: 0.9777\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 0.1064 - accuracy: 0.9698 - val_loss: 0.0647 - val_accuracy: 0.9840\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0999 - accuracy: 0.9714 - val_loss: 0.0763 - val_accuracy: 0.9803\n",
            "Epoch 4: early stopping\n",
            "Generation 18:\t\tbest accuracy: 0.9818\t\taverage:0.9795\t\tstd: 0.0023\n",
            "\n",
            "model 1/2 - generation 19/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 18s 10ms/step - loss: 1.1213 - accuracy: 0.7796 - val_loss: 0.3158 - val_accuracy: 0.9210\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.3935 - accuracy: 0.9131 - val_loss: 0.1369 - val_accuracy: 0.9720\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.2556 - accuracy: 0.9444 - val_loss: 0.1137 - val_accuracy: 0.9767\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.2030 - accuracy: 0.9551 - val_loss: 0.1513 - val_accuracy: 0.9673\n",
            "Epoch 4: early stopping\n",
            "\n",
            "model 2/2 - generation 19/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.3266 - accuracy: 0.9055 - val_loss: 0.0994 - val_accuracy: 0.9738\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1155 - accuracy: 0.9668 - val_loss: 0.0803 - val_accuracy: 0.9802\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0972 - accuracy: 0.9716 - val_loss: 0.0746 - val_accuracy: 0.9818\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0928 - accuracy: 0.9733 - val_loss: 0.0671 - val_accuracy: 0.9828\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0897 - accuracy: 0.9745 - val_loss: 0.0761 - val_accuracy: 0.9810\n",
            "Epoch 5: early stopping\n",
            "Generation 19:\t\tbest accuracy: 0.9780\t\taverage:0.9724\t\tstd: 0.0056\n",
            "\n",
            "model 1/2 - generation 20/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.3507 - accuracy: 0.8976 - val_loss: 0.1037 - val_accuracy: 0.9717\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1181 - accuracy: 0.9653 - val_loss: 0.0745 - val_accuracy: 0.9837\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1004 - accuracy: 0.9706 - val_loss: 0.0701 - val_accuracy: 0.9798\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0911 - accuracy: 0.9736 - val_loss: 0.0687 - val_accuracy: 0.9827\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0912 - accuracy: 0.9746 - val_loss: 0.0649 - val_accuracy: 0.9838\n",
            "\n",
            "model 2/2 - generation 20/20:\n",
            "\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 18s 10ms/step - loss: 1.1165 - accuracy: 0.7795 - val_loss: 0.3877 - val_accuracy: 0.9085\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.3756 - accuracy: 0.9138 - val_loss: 0.1541 - val_accuracy: 0.9655\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.2403 - accuracy: 0.9442 - val_loss: 0.2827 - val_accuracy: 0.9430\n",
            "Epoch 3: early stopping\n",
            "Generation 20:\t\tbest accuracy: 0.9808\t\taverage:0.9597\t\tstd: 0.0211\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_42 (Conv2D)          (None, 28, 28, 128)       1280      \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 28, 28, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_42 (Activation)  (None, 28, 28, 128)       0         \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 28, 28, 128)       0         \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 28, 28, 16)        18448     \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 28, 28, 16)       64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_43 (Activation)  (None, 28, 28, 16)        0         \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 28, 28, 16)        0         \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 28, 28, 8)         1160      \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 28, 28, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_44 (Activation)  (None, 28, 28, 8)         0         \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 28, 28, 8)         0         \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                62730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84,226\n",
            "Trainable params: 83,922\n",
            "Non-trainable params: 304\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vkPwFG5qp-Ew"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}